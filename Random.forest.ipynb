{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREFA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- PASSO A PASSO PARA O ALGORITIMO RF\n",
    "\n",
    "técnica de aprendizado de conjunto baseada em árvores de decisão\n",
    "\n",
    "Conjunto de Dados de Treinamento:\n",
    "\n",
    "Comece com um conjunto de dados de treinamento que contenha exemplos rotulados (características e suas saídas correspondentes).\n",
    "\n",
    "Amostragem Bootstrap:\n",
    "\n",
    "Realize amostragem com substituição no conjunto de dados de treinamento para criar múltiplos conjuntos de dados de treinamento. Cada conjunto de dados é uma amostra Bootstrap do conjunto de treinamento original.\n",
    "\n",
    "Construção de Árvores de Decisão:\n",
    "\n",
    "Para cada um desses conjuntos de dados de treinamento (obtidos por amostragem Bootstrap), construa uma árvore de decisão. Cada árvore é treinada de forma independente com uma amostra diferente.\n",
    "\n",
    "Randomização das Árvores:\n",
    "\n",
    "Durante a construção de cada árvore de decisão, em cada divisão do nó, uma subamostra aleatória de características é considerada para escolher a melhor divisão. Isso ajuda a introduzir aleatoriedade e a reduzir a correlação entre as árvores.\n",
    "\n",
    "Agregação (Combinação) das Árvores:\n",
    "\n",
    "Para problemas de regressão, a previsão final é geralmente a média das previsões de todas as árvores.\n",
    "Para problemas de classificação, o voto majoritário é usado para determinar a classe final prevista.\n",
    "\n",
    "Redução da Variância e Overfitting:\n",
    "\n",
    "A técnica de combinação de várias árvores ajuda a reduzir a variância e o overfitting que podem ser observados em árvores de decisão individuais.\n",
    "\n",
    "Parâmetros Importantes:\n",
    "\n",
    "Alguns parâmetros-chave para ajustar incluem o número de árvores na floresta, a profundidade máxima das árvores individuais, o número mínimo de amostras para divisão de um nó, entre outros, que podem afetar o desempenho do modelo.\n",
    "\n",
    "Avaliação do Modelo:\n",
    "\n",
    "O desempenho do modelo Random Forest é geralmente avaliado usando métricas de avaliação apropriadas para o problema, como acurácia, F1-score, erro quadrático médio (RMSE), entre outras.\n",
    "O Random Forest é uma técnica poderosa que geralmente produz bons resultados em muitos tipos de conjuntos de dados. Ele aproveita a força do conjunto de árvores de decisão para realizar previsões robustas e estáveis, além de ser menos propenso a overfitting em comparação com árvores de decisão individuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF\n",
    "\n",
    "Assim como o Bagging, Random Forest também é um método de aprendizagem em conjunto (Ensemble Learning) para classificações, regressões e algumas outras tarefas e funciona construindo várias árvores de decisão. Normalmente uma árvore de decisão com grande profundidade tende a aprender padrões irregulares e acaba ocorrendo overfitting com a base de treino. O Random Forest é uma maneira de calcular uma média de várias árvores com grande profundidade treinadas em diferentes partes do mesmo conjunto de treinamento, com o objetivo de reduzir a variância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIFERENÇA ENTRE BAGGING E RANDOM FOREST\n",
    "\n",
    "Random Forest é focado em utilizarmos modelos de Árvore de Decisão, já o Bagging é mais aberto a outros modelos, por exemplo os de regressão linear ou logistica. Na hora de separar a base de treino inicial o Bagging leva em conta apenas as linhas, já o Random Forest utiliza também uma separação nas colunas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Random Forest: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar conjunto de dados \n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Modelagem com Decision Trees\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Seleção de características usando importância das features da Decision Tree\n",
    "feature_selection = SelectFromModel(decision_tree, threshold='median')\n",
    "feature_selection.fit(X_train, y_train)\n",
    "X_train_selected = feature_selection.transform(X_train)\n",
    "X_test_selected = feature_selection.transform(X_test)\n",
    "\n",
    "# Random Forest com feature selection\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_selected, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predictions = random_forest.predict(X_test_selected)\n",
    "\n",
    "# Calcular a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Acurácia do modelo Random Forest: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
