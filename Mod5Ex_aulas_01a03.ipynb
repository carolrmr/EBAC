{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 5 Tarefa 1\n",
    "## Base de nascidos vivos do DataSUS\n",
    "O DataSUS disponibiliza diversos arquivos de dados com relação a seus segurados, conforme a [lei da transparência de informações públicas](https://www.sisgov.com/transparencia-acesso-informacao/#:~:text=A%20Lei%20da%20Transpar%C3%AAncia%20(LC,em%20um%20site%20na%20internet.). \n",
    "\n",
    "Essas informações podem ser obtidas pela internet [aqui](http://www2.datasus.gov.br/DATASUS/index.php?area=0901&item=1). Como o processo de obtenção desses arquivos foge um pouco do nosso escopo, deixamos o arquivo ```SINASC_RO_2019.csv``` já como vai ser encontrado no DataSUS. O dicionário de dados está no arquivo ```estrutura_sinasc_para_CD.pdf``` (o nome do arquivo tal qual no portal do DataSUS).\n",
    "\n",
    "### Nosso objetivo\n",
    "Queremos deixar uma base organizada para podermos estudar a relação entre partos com risco para o bebê e algumas condições como tempo de parto, consultas de pré-natal etc.\n",
    "\n",
    "#### Preparação da base\n",
    "1. Carregue a base 'SINASC_RO_2019.csv'. Conte o número de registros e o número de registros não duplicados da base. Dica: você aprendeu um método que remove duplicados, encadeie este método com um outro método que conta o número de linhas. **Há linhas duplicadas?**  \n",
    "\n",
    "2. Conte o número de valores *missing* por variável.  \n",
    "\n",
    "3. Ok, no item anterior você deve ter achado pouco prático ler a informação de tantas variáveis, muitas delas nem devem ser interesantes. Então crie uma seleção dessa base somente com as colunas que interessam. São elas:\n",
    "``` \n",
    "['LOCNASC', 'IDADEMAE', 'ESTCIVMAE', 'ESCMAE', 'QTDFILVIVO', \n",
    "    'GESTACAO', 'GRAVIDEZ', 'CONSULTAS', 'APGAR5'] \n",
    "```\n",
    "Refaça a contagem de valores *missings*.  \n",
    "\n",
    "4. Apgar é uma *nota* que o pediatra dá ao bebê quando nasce de acordo com algumas características associadas principalmente à respiração. Apgar 1 e Apgar 5 são as notas 1 e 5 minutos do nascimento. Apgar5 será a nossa variável de interesse principal. Então remova todos os registros com Apgar5 não preenchido. Para esta seleção, conte novamente o número de linhas e o número de *missings*.  \n",
    "\n",
    "5. observe que as variáveis ```['ESTCIVMAE', 'CONSULTAS']``` possuem o código ```9```, que significa *ignorado*. Vamos assumir que o não preenchido é o mesmo que o código ```9```.<br>\n",
    "6. Substitua os valores faltantes da quantitativa (```QTDFILVIVO```) por zero.  \n",
    "7. Das restantes, decida que valore te parece mais adequado (um 'não preenchido' ou um valor 'mais provável' como no item anterior) e preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do cientista, e que estamos tomando decisões a todo o momento - não há necessariamente certo e errado aqui.  \n",
    "8. O Apgar possui uma classificação indicando se o bebê passou por asfixia:\n",
    "- Entre 8 e 10 está em uma faixa 'normal'. \n",
    "- Entre 6 e 7, significa que o recém-nascido passou por 'asfixia leve'. \n",
    "- Entre 4 e 5 significa 'asfixia moderada'.\n",
    "- Entre 0 e 3 significa 'asfixia severa'.  \n",
    "\n",
    "Crie uma categorização dessa variável com essa codificação e calcule as frequências dessa categorização.  \n",
    "<br>\n",
    "9. Renomeie as variáveis para que fiquem no *snake case*, ou seja, em letras minúsculas, com um *underscore* entre as palávras. Dica: repare que se você não quiser criar um *dataframe* novo, você vai precisar usar a opção ```inplace = True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27028, 69)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27028, 69)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# 1) seu código aqui\n",
    "sinasc = pd.read_csv('SINASC_RO_2019.csv')\n",
    "print(sinasc.shape)\n",
    "sinasc.drop_duplicates().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGEM          0\n",
      "CODESTAB      115\n",
      "CODMUNNASC      0\n",
      "LOCNASC         0\n",
      "IDADEMAE        0\n",
      "             ... \n",
      "munResUf        0\n",
      "munResLat       1\n",
      "munResLon       1\n",
      "munResAlt       1\n",
      "munResArea      1\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) seu código aqui\n",
    "\n",
    "\n",
    "# Carregando a base de dados\n",
    "dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "\n",
    "# Contando o número de valores missing por variável\n",
    "valores_missing = dataframe.isna().sum()\n",
    "\n",
    "print(valores_missing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCNASC          0\n",
      "IDADEMAE         0\n",
      "ESTCIVMAE      317\n",
      "ESCMAE         312\n",
      "QTDFILVIVO    1573\n",
      "GESTACAO      1232\n",
      "GRAVIDEZ        79\n",
      "CONSULTAS        0\n",
      "APGAR5         103\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Carregando a base de dados completa\n",
    "dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "\n",
    "# Selecionando as colunas de interesse\n",
    "colunas_interesse = ['LOCNASC', 'IDADEMAE', 'ESTCIVMAE', 'ESCMAE', 'QTDFILVIVO', 'GESTACAO', 'GRAVIDEZ', 'CONSULTAS', 'APGAR5']\n",
    "dataframe_interesse = dataframe[colunas_interesse]\n",
    "\n",
    "# Contando o número de valores missing por variável\n",
    "valores_missing = dataframe_interesse.isna().sum()\n",
    "\n",
    "print(valores_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros: 26925\n",
      "Número de missings por variável:\n",
      "ORIGEM         0\n",
      "CODESTAB      66\n",
      "CODMUNNASC     0\n",
      "LOCNASC        0\n",
      "IDADEMAE       0\n",
      "              ..\n",
      "munResUf       0\n",
      "munResLat      1\n",
      "munResLon      1\n",
      "munResAlt      1\n",
      "munResArea     1\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4) seu código aqui\n",
    "\n",
    "\n",
    "# Carregando a base de dados completa\n",
    "dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "\n",
    "# Selecionando apenas os registros com APGAR5 preenchido\n",
    "dataframe_interesse = dataframe.dropna(subset=['APGAR5'])\n",
    "\n",
    "# Contando o número de linhas e valores missing após a remoção\n",
    "num_registros = len(dataframe_interesse)\n",
    "valores_missing = dataframe_interesse.isna().sum()\n",
    "\n",
    "print(\"Número de registros:\", num_registros)\n",
    "print(\"Número de missings por variável:\")\n",
    "print(valores_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos de ESTCIVMAE após a substituição:\n",
      "[ 5.  2. nan  1.  4.  3.]\n",
      "\n",
      "Valores únicos de CONSULTAS após a substituição:\n",
      "[ 4.  3.  2.  1. nan]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carregando a base de dados completa\n",
    "dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "\n",
    "# Substituindo o código \"9\" por NaN nas variáveis 'ESTCIVMAE' e 'CONSULTAS'\n",
    "dataframe['ESTCIVMAE'].replace(9, np.nan, inplace=True)\n",
    "dataframe['CONSULTAS'].replace(9, np.nan, inplace=True)\n",
    "\n",
    "# Verificando os valores únicos após a substituição\n",
    "valores_unicos_ESTCIVMAE = dataframe['ESTCIVMAE'].unique()\n",
    "valores_unicos_CONSULTAS = dataframe['CONSULTAS'].unique()\n",
    "\n",
    "print(\"Valores únicos de ESTCIVMAE após a substituição:\")\n",
    "print(valores_unicos_ESTCIVMAE)\n",
    "print(\"\\nValores únicos de CONSULTAS após a substituição:\")\n",
    "print(valores_unicos_CONSULTAS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos após a substituição:\n",
      "[ 0.  1.  2.  3.  4.  6.  5.  7. 12.  9. 11.  8. 30. 10. 14.]\n"
     ]
    }
   ],
   "source": [
    "# 5) seu código aqui\n",
    "\n",
    "\n",
    "# Carregando a base de dados completa\n",
    "dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "\n",
    "# Substituindo os valores faltantes de 'QTDFILVIVO' por zero\n",
    "dataframe['QTDFILVIVO'] = dataframe['QTDFILVIVO'].fillna(0)\n",
    "\n",
    "# Verificando os valores únicos após a substituição\n",
    "valores_unicos = dataframe['QTDFILVIVO'].unique()\n",
    "\n",
    "print(\"Valores únicos após a substituição:\")\n",
    "print(valores_unicos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0113955897587688"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) seu código aqui\n",
    "df = dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "df['LOCNASC'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['LOCNASC'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.093717626165457"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IDADEMAE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IDADEMAE'].median()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores mais provaveis :\n",
      " 1.0, 26.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nValores mais provaveis :\")\n",
    "print(' 1.0, 26.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APGAR5_Categoria\n",
      "normal              18311\n",
      "asfixia leve          124\n",
      "asfixia severa         59\n",
      "asfixia moderada       38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 8) seu código aqui\n",
    "\n",
    "# Carregando a base de dados completa\n",
    "dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "\n",
    "# Categorizando a variável 'APGAR5'\n",
    "categorias = [0, 3, 5, 7, 10]\n",
    "labels = ['asfixia severa', 'asfixia moderada', 'asfixia leve', 'normal']\n",
    "dataframe['APGAR5_Categoria'] = pd.cut(dataframe['APGAR5'], bins=categorias, labels=labels, right=False)\n",
    "\n",
    "# Calculando as frequências da categorização\n",
    "frequencias = dataframe['APGAR5_Categoria'].value_counts()\n",
    "\n",
    "print(frequencias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['origem', 'codestab', 'codmunnasc', 'locnasc', 'idademae', 'estcivmae',\n",
      "       'escmae', 'codocupmae', 'qtdfilvivo', 'qtdfilmort', 'codmunres',\n",
      "       'gestacao', 'gravidez', 'parto', 'consultas', 'dtnasc', 'horanasc',\n",
      "       'sexo', 'apgar1', 'apgar5', 'racacor', 'peso', 'idanomal', 'dtcadastro',\n",
      "       'codanomal', 'numerolote', 'versaosist', 'dtrecebim', 'difdata',\n",
      "       'dtrecoriga', 'naturalmae', 'codmunnatu', 'codufnatu', 'escmae2010',\n",
      "       'seriescmae', 'dtnascmae', 'racacormae', 'qtdgestant', 'qtdpartnor',\n",
      "       'qtdpartces', 'idadepai', 'dtultmenst', 'semagestac', 'tpmetestim',\n",
      "       'consprenat', 'mesprenat', 'tpapresent', 'sttrabpart', 'stcesparto',\n",
      "       'tpnascassi', 'tpfuncresp', 'tpdocresp', 'dtdeclarac', 'escmaeagr1',\n",
      "       'stdnepidem', 'stdnnova', 'codpaisres', 'tprobson', 'paridade',\n",
      "       'kotelchuck', 'contador', 'munresstatus', 'munrestipo', 'munresnome',\n",
      "       'munresuf', 'munreslat', 'munreslon', 'munresalt', 'munresarea'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 9) seu código aqui\n",
    "\n",
    "\n",
    "# Carregando a base de dados completa\n",
    "dataframe = pd.read_csv('SINASC_RO_2019.csv')\n",
    "\n",
    "# Renomeando as variáveis para snake case\n",
    "dataframe.rename(columns=lambda x: x.lower().replace(\" \", \"_\"), inplace=True)\n",
    "\n",
    "# Verificando o novo nome das variáveis\n",
    "print(dataframe.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
